// Package kafka provides a Kafka abstraction through github.com/Shopify/sarama.
//
// WARNING: there's no message ack-ing done by Subscriber, so no automatic resuming from last-processed message.
// Subscribing is done only from oldest-known or newest or manually-specified numeric offset.
//
// Both bps.NewPublisher (`kafka` + `kafka+sync` schemes) and bps.NewConsumer (`kafka` scheme)
// support the following query parameters:
//
//   client.id
//      A user-provided string sent with every request to the brokers for logging debugging, and auditing
//      purposes.
//   kafka.version
//      The version of the kafka server.
//   channel.buffer.size
//      The number of events to buffer in internal and external channels. This permits the producer to
//      continue processing some messages in the background while user code is working, greatly improving
//      throughput (default 256).
//
// bps.NewPublisher supports `kafka` + `kafka+sync` schemes and the following query parameters:
//
//   acks
//      The number of acks required before considering a request complete. When acks=0, the producer will
//      not wait for any acknowledgment. When acks=1 the leader will write the record to its local log but
//      will respond without awaiting full acknowledgement from all followers. When acks=all the leader will
//      wait for the full set of in-sync replicas to acknowledge the record.
//   message.max.bytes
//      The maximum permitted size of a message (default 1,000,000). Should be
//      set equal to or smaller than the broker's `message.max.bytes`.
//   compression.type
//      The compression type for all data generated by the producer. Valid values are: none, gzip, snappy,
//      lz4 (default none).
//   partitioner
//      The partitioner used to partition messages (defaults to hashing the message ID). Valid values are:
//      hash, random, roundrobin,
//   timeout
//      The maximum duration the broker will wait the receipt of the number of acks (default 10s).
//      This is only relevant when acks=all or a number > 1.
//   flush.bytes
//      he best-effort number of bytes needed to trigger a flush.
//   flush.messages
//      The best-effort number of messages needed to trigger a flush.
//   flush.frequency
//      The best-effort frequency of flushes.
//   retry.max
//      The total number of times to retry sending a message (default 3).
//   retry.backoff
//      How long to wait for the cluster to settle between retries (default 100ms).
//
// bps.NewConsumer (`kafka://` scheme) supports:
//
//   offsets.initial
//     Offset to start consuming from. Can be "oldest" (oldest available message)
//     or "newest" (only new messages - produced after subscribing)
//     or just numeric offset value.
//
package kafka

import (
	"context"
	"errors"
	"fmt"
	"net/url"

	"github.com/Shopify/sarama"
	"github.com/bsm/bps"
	"go.uber.org/multierr"
	"golang.org/x/sync/errgroup"
)

func init() {
	bps.RegisterPublisher("kafka", func(ctx context.Context, u *url.URL) (bps.Publisher, error) {
		config := parseProducerQuery(u.Query())
		config.Producer.Return.Errors = false
		return NewPublisher(parseAddrs(u), config)
	})

	bps.RegisterPublisher("kafka+sync", func(ctx context.Context, u *url.URL) (bps.Publisher, error) {
		config := parseProducerQuery(u.Query())
		config.Producer.Return.Successes = true
		return NewSyncPublisher(parseAddrs(u), config)
	})

	bps.RegisterSubscriber("kafka", func(ctx context.Context, u *url.URL) (bps.Subscriber, error) {
		config := parseSubscriberQuery(u.Query())
		config.Consumer.Return.Errors = false
		return NewSubscriber(parseAddrs(u), config)
	})
}

// --------------------------------------------------------------------

// Publisher wraps a kafka producer and implements the bps.Publisher interface.
type Publisher struct {
	producer sarama.AsyncProducer
}

// NewPublisher inits a new async publisher.
func NewPublisher(addrs []string, config *sarama.Config) (*Publisher, error) {
	producer, err := sarama.NewAsyncProducer(addrs, config)
	if err != nil {
		return nil, err
	}
	return &Publisher{producer: producer}, nil
}

// Topic implements the bps.Publisher interface.
func (p *Publisher) Topic(name string) bps.Topic {
	return &topicAsync{name: name, producer: p.producer}
}

// Close implements the bps.Publisher interface.
func (p *Publisher) Close() error {
	return p.producer.Close()
}

// Producer exposes the native producer. Use at your own risk!
func (p *Publisher) Producer() sarama.AsyncProducer {
	return p.producer
}

type topicAsync struct {
	name     string
	producer sarama.AsyncProducer
}

// Publish implements the bps.Topic interface.
func (t *topicAsync) Publish(_ context.Context, msg *bps.PubMessage) error {
	t.producer.Input() <- convertMessage(t.name, msg)
	return nil
}

// PublishBatch implements the bps.Topic interface.
func (t *topicAsync) PublishBatch(ctx context.Context, batch []*bps.PubMessage) error {
	for _, msg := range batch {
		if err := t.Publish(ctx, msg); err != nil {
			return err
		}
	}
	return nil
}

// --------------------------------------------------------------------

// SyncPublisher wraps a synchronous kafka producer and implements the bps.Publisher interface.
type SyncPublisher struct {
	producer sarama.SyncProducer
}

// NewSyncPublisher inits a new async publisher.
func NewSyncPublisher(addrs []string, config *sarama.Config) (*SyncPublisher, error) {
	producer, err := sarama.NewSyncProducer(addrs, config)
	if err != nil {
		return nil, err
	}
	return &SyncPublisher{producer: producer}, nil
}

// Topic implements the bps.Publisher interface.
func (p *SyncPublisher) Topic(name string) bps.Topic {
	return &topicSync{name: name, producer: p.producer}
}

// Close implements the bps.Publisher interface.
func (p *SyncPublisher) Close() error {
	return p.producer.Close()
}

// Producer exposes the native producer. Use at your own risk!
func (p *SyncPublisher) Producer() sarama.SyncProducer {
	return p.producer
}

type topicSync struct {
	name     string
	producer sarama.SyncProducer
}

// Publish implements the bps.Topic interface.
func (t *topicSync) Publish(_ context.Context, msg *bps.PubMessage) error {
	_, _, err := t.producer.SendMessage(convertMessage(t.name, msg))
	return err
}

// PublishBatch implements the bps.Topic interface.
func (t *topicSync) PublishBatch(ctx context.Context, batch []*bps.PubMessage) error {
	if len(batch) == 0 {
		return nil
	}

	pmsgs := make([]*sarama.ProducerMessage, len(batch))
	for i, msg := range batch {
		pmsgs[i] = convertMessage(t.name, msg)
	}
	return t.producer.SendMessages(pmsgs)
}

// --------------------------------------------------------------------

// Subscriber wraps a kafka consumer and implements the bps.Subscriber interface.
// It starts consuming from the newest offset (so from message, received after connecting to kafka).
type Subscriber struct {
	consumer      sarama.Consumer
	initialOffset int64
}

// NewSubscriber inits a new subscriber.
func NewSubscriber(addrs []string, config *sarama.Config) (*Subscriber, error) {
	consumer, err := sarama.NewConsumer(addrs, config)
	if err != nil {
		return nil, err
	}
	return &Subscriber{
		consumer:      consumer,
		initialOffset: config.Consumer.Offsets.Initial,
	}, nil
}

// Subscribe implements the bps.Subscriber interface.
func (s *Subscriber) Subscribe(ctx context.Context, topic string, handler bps.Handler) error {
	// get partitions before spawning anything to do less cleanup on failure:
	partitions, err := s.consumer.Partitions(topic)
	if err != nil {
		return fmt.Errorf("get %s partitions: %w", topic, err)
	}

	// cancelable ctx to signal background partition-consuming goroutines to exit:
	ctx, cancel := context.WithCancel(ctx)
	defer cancel()

	// multiplexed messages channel to call handler sequentially:
	messages := make(chan bps.SubMessage)
	defer close(messages)

	// spawn/manage partition-consuming goroutines:
	consumers, ctx := errgroup.WithContext(ctx)
	for _, partition := range partitions {
		partition := partition // https://golang.org/doc/faq#closures_and_goroutines

		consumers.Go(func() error {
			pc, err := s.consumer.ConsumePartition(topic, partition, s.initialOffset)
			if err != nil {
				return fmt.Errorf("consume %s/%d partition: %w", topic, partition, err)
			}
			defer pc.Close()

			for {
				select {
				case <-ctx.Done():
					return nil // no errors caused by THIS goroutine

				case msg, more := <-pc.Messages():
					if !more {
						return bps.Done // normal exit
					}
					select {
					case messages <- bps.RawSubMessage(msg.Value):
					case <-ctx.Done():
						return nil // no errors, this `case` may/will be reached only if multiplexed `messages` are not handled anymore
					}
				}
			}
		})
	}

	for {
		select {
		case <-ctx.Done():
			return convertDoneErr(consumers.Wait())

		case msg := <-messages:
			if err := handler.Handle(msg); err != nil {
				cancel() // signal background goroutines to exit
				return multierr.Combine(
					convertDoneErr(err),
					convertDoneErr(consumers.Wait()),
				)
			}
		}
	}
}

// Close implements the bps.Subscriber interface.
func (s *Subscriber) Close() error {
	return s.consumer.Close()
}

// convertDoneErr suppresses `bps.Done` error,
// as it is used to indicate success.
func convertDoneErr(err error) error {
	if errors.Is(err, bps.Done) {
		return nil
	}
	return err
}
